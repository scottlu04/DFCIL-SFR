few_shot_size: 5
in_channels: &in_channels 3
seq_len: &seq_len 64
rm_global_scale: &rm_global_scale On
batch_size: 64
workers: 4
total_epochs: 10
total_epochs_incremental_task: 0
step_per_epoch: &step_per_epoch On
step_per_batch: &step_per_batch Off
log_freq:
    train: 20
    val: null

model:
    name: 'stgcn_contrastive'
    n_joints: 25
    graph_cfg: 
        layout: 'nturgb+d'
        mode: 'spatial'
    gcn_adaptive: 'init' 
    gcn_with_res: True
    tcn_type: 'mstcn'
    dropout: 0.5
    in_channels: 3
    base_channels: 64
    d_feat: 256

transforms:
    # window_size: *seq_len
    # p_interval: [0.5, 1]
    train:

        PreNormalize3D:
            zaxis: [0, 1] 
            xaxis: [8, 4]
            align_spine: True
            align_center: True

        GenSkeFeat:
            dataset: 'nturgb+d'
            feats: ['j']
            axis: -1

        UniformSampleFrames:
            clip_len: *seq_len
            num_clips: 1
            p_interval: 1
            seed: 255
        PoseDecode:
        FormatGCNInput:
            num_person: 2
            mode: 'zero'
            

               
    val: &transforms_inference
        PreNormalize3D:
            zaxis: [0, 1] 
            xaxis: [8, 4]
            align_spine: True
            align_center: True

        GenSkeFeat:
            dataset: 'nturgb+d'
            feats: ['j']
            axis: -1

        UniformSampleFrames:
            clip_len: 100
            num_clips: 1
            p_interval: 1
            seed: 255
        PoseDecode:
        FormatGCNInput:
            num_person: 2
            mode: 'zero'
            
    testval: *transforms_inference  
    testtrain: *transforms_inference 
    test: *transforms_inference  




loss:
    contrastive: 
        weight: 1.0
        n_views: *n_views
        is_supervised: On
        temperature: 0.07
    cross_entropy: 
        weight: 1.0
        ignore: null
        class_weight: null


optimizer:
    name: 'sgd'
    lr: &lr 0.1
    lr_incremental_task: 0.005
    classifier_lr: 0.1
    betas: [0.9, 0.999]
    include_scheduler: False
    scheduler:
        name: 'linear'
        lr: *lr
        start_factor: 1
        end_factor: 0.001
        step_per_batch: *step_per_batch
        step_per_epoch: *step_per_epoch      
          

increm:
    load_pretrained_task0: True
    first_split_size: 60
    other_split_size: 24 
    max_task: 7
    load_best_checkpoint_train: True  # Only for task_id == 1
    load_best_checkpoint_test: False # Only for task_id == 1
    freeze_feature_extractor: False
    freeze_classifier: False
    memory: 0
    learner:
        type: 'cts'
        n_samples_per_class: 300
        power_iters: 5000          
        deep_inv_params: [1, 50, 0.001, 10, 1, -0.5, 5]  
        inversion_batch_size: 32
        inverted_acc_thred: 99

